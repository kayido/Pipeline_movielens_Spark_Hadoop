# BigDataProject - Pipeline ETL MovieLens

## ğŸ“‹ Description

**BigDataProject** est un projet de traitement de donnÃ©es massives basÃ© sur un **pipeline ETL** complet. Il traite le dataset MovieLens en utilisant une architecture Big Data moderne avec **Apache Hadoop**, **Apache Spark**, et **Hive**.

Le projet dÃ©montre les Ã©tapes complÃ¨tes d un pipeline ETL :
- **Extract** : Extraction des donnÃ©es brutes depuis des fichiers CSV
- **Transform** : Nettoyage, enrichissement et transformation avec PySpark et Hive
- **Load** : Chargement des rÃ©sultats dans HDFS

## ğŸ—ï¸ Architecture

```
DonnÃ©es brutes (CSV)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 1: Extraction (spark-etl.py)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 2: Transformation (Spark/Hive)   â”‚
â”‚  - Nettoyage des donnÃ©es                â”‚
â”‚  - Jointures et agrÃ©gations             â”‚
â”‚  - Calculs de mÃ©triques                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Stage 3: Chargement (HDFS)             â”‚
â”‚  - Silver layer (donnÃ©es traitÃ©es)      â”‚
â”‚  - Results layer (rÃ©sultats d analyse)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Structure du Projet

```
BigDataProject/
â”œâ”€â”€ spark-etl.py                 # Script principal de transformation PySpark
â”œâ”€â”€ hive-etl.hql                 # RequÃªtes Hive pour analyses avancÃ©es
â”œâ”€â”€ etl.ipynb                    # Notebook Jupyter pour exploration 
â”œâ”€â”€ full_dataset_v2.csv          # Dataset complet consolidÃ©
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ docker-compose.yml       # Configuration du cluster Hadoop
â””â”€â”€ ml-latest/                   # Dataset MovieLens original
    â”œâ”€â”€ movies.csv               # DonnÃ©es des films
    â”œâ”€â”€ ratings.csv              # DonnÃ©es des Ã©valuations
    â”œâ”€â”€ tags.csv                 # Tags attribuÃ©s aux films
    â”œâ”€â”€ links.csv                # Identifiants externes (IMDb, TMDb)
    â”œâ”€â”€ genome-scores.csv        # Scores de genome (tags)
    â””â”€â”€ genome-tags.csv          # DÃ©finitions des tags du genome
```

## ğŸš€ Getting Started

### PrÃ©requis

- **Docker** et **Docker Compose** pour l infrastructure
- **Python 3.8+** pour PySpark
- **Java 8+** pour Hadoop/Spark
- **Jupyter Notebook** (optionnel) pour l exploration interactive

### Installation

#### 1. DÃ©marrer le cluster Hadoop

```bash
cd docker
docker-compose up -d
```
ou
 Avec Docker Desktop et VsCode Remote , ouvrez le dossier `docker` et lancez le conteneur.

Cela dÃ©marre :
- **hadoop-master** : NameNode et ResourceManager
- **hadoop-worker1** et **hadoop-worker2** : DataNodes

VÃ©rifiez l Ã©tat du cluster sur `http://localhost:9870` (NameNode UI)

#### 2. Charger les donnÃ©es dans HDFS

```bash
# CrÃ©er les rÃ©pertoires dans HDFS
./start-hadoop.sh
hdfs dfs -mkdir -p /user/root/raw

# Copier les fichiers MovieLens dans le conteneur Hadoop
docker  cp ml-latest/movies.csv hadoop-master-project:/tmp/movies.csv.csv
docker  cp ml-latest/ratings.csv hadoop-master-project:/tmp/ratings.csv

# Depuis le conteneur Hadoop, dÃ©placer les fichiers dans HDFS
hdfs dfs -put /tmp/movies.csv /user/root/raw/
hdfs dfs -put /tmp/ratings.csv /user/root/raw/
```

#### 3. ExÃ©cuter le pipeline PySpark

```bash
# Copier les scripts dans le conteneur Hadoop
docker cp spark-etl.py hadoop-master-project:/tmp/spark-etl.py
docker cp hive-etl.hql hadoop-master-project:/tmp/hive-etl.hql

# Depuis le conteneur Hadoop, exÃ©cuter le script PySpark
spark-submit /tmp/spark-etl.py
hive -f /tmp/hive-etl.hql
```

### Utilisation

#### ğŸ” Exploration avec Jupyter

```bash
jupyter notebook etl.ipynb
```

Le notebook contient :
- Chargement et exploration des donnÃ©es
- Visualisations des distributions
- Analyses prÃ©liminaires

#### ğŸ“Š RequÃªtes Hive avancÃ©es

```bash
docker exec hadoop-master-project hive -f hive-etl.hql
```

Le fichier Hive contient des requÃªtes pour :
- Top films par genre
- Films les mieux notÃ©s ...

## ğŸ“Š Dataset MovieLens

Le projet utilise le dataset **MovieLens ml-latest** qui contient :
- **27 878 films**
- **1 108 997 Ã©valuations**
- **65 133 tags**
- **Tags gÃ©nÃ©tiques** (genome scores)

### Fichiers disponibles

| Fichier | Description |
|---------|-------------|
| `movies.csv` | ID, titre, genres |
| `ratings.csv` | ID utilisateur, ID film, note, timestamp |
| `tags.csv` | ID utilisateur, ID film, tag, timestamp |
| `links.csv` | Identifiants IMDb et TMDb |
| `genome-scores.csv` | Scores de pertinence des tags |
| `genome-tags.csv` | Description des tags du genome |

## âš™ï¸ Configuration

### Chemins HDFS

Modifiez les constantes dans `spark-etl.py` pour personnaliser les chemins :

```python
RAW_BASE = "hdfs:///user/root/raw"         # donnÃ©es brutes
SILVER_OUT = "hdfs:///user/root/silver"    # donnÃ©es transformÃ©es
RESULTS_OUT = "hdfs:///user/root/results"  # rÃ©sultats finaux
```

## ğŸ³ Services Docker

### Commandes utiles


# AccÃ©der au shell du conteneur
docker exec -it hadoop-master-project bash

# Lister les fichiers HDFS
hdfs dfs -ls /

# ArrÃªter le cluster
docker-compose down
```

## ğŸ“ˆ Pipeline DÃ©taillÃ©

### Ã‰tape 1 : Extraction (Extract)
```python
# Lecture des fichiers CSV depuis HDFS
movies = spark.read.csv("hdfs:///user/root/raw/movies.csv")
ratings = spark.read.csv("hdfs:///user/root/raw/ratings.csv")
```

### Ã‰tape 2 : Transformation (Transform)
- Typage des colonnes (strings â†’ nombres)
- Nettoyage des valeurs manquantes
- Jointures entre tables
- AgrÃ©gations et calculs de mÃ©triques
- FenÃªtrage pour analyses temporelles

### Ã‰tape 3 : Chargement (Load)
```python
# Ã‰criture des rÃ©sultats
transformed_data.write.mode("overwrite").csv("hdfs:///user/root/results/")
```

## ğŸ”§ Troubleshooting


**ProblÃ¨me** : DonnÃ©es introuvables dans HDFS
```bash
# Lister et vÃ©rifier les fichiers
docker exec hadoop-master-project hdfs dfs -ls /user/root/raw/
```

## ğŸ“ Notes

- Les donnÃ©es complÃ¨tes sont consolidÃ©es dans `full_dataset_v2.csv`


## ğŸ“„ Licence

DonnÃ©es MovieLens : [License MovieLens](https://grouplens.org/datasets/movielens/)
